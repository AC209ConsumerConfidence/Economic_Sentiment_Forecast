{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification Using SentiWordNet\n",
    "\n",
    "For sentiment classification, one approach is to use the [SentiWordNet](http://nmis.isti.cnr.it/sebastiani/Publications/LREC06.pdf) word dictionary, which builds on top of the original Princeton [WordNet](https://wordnet.princeton.edu) dictionary by adding sentiment scores to each word. In addition to sentiments, it also gives an objectivity score, which is a measure of.\n",
    "\n",
    "It is possible to download the original [SentiWordNet data files](http://sentiwordnet.isti.cnr.it/), but luckily NLTK provides an already parsed version of the same corpus, along with convenience functions to search the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To download the SentiWordNet and stopword corpora, run the commands below\n",
    "nltk.download(\"sentiwordnet\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try it on one word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plant01 = swn.senti_synset(\"plant.n.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plant01.neg_score(), plant01.pos_score(), plant01.obj_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that this is a very specific \"sense\" of a word. \"plant.n.01\" means \"the first meaning of the word \"plant\", that is a noun. Wordnet provides many meanings of words. You can search for multiple, like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('plant.n.01'),\n",
       " SentiSynset('plant.n.02'),\n",
       " SentiSynset('plant.n.03'),\n",
       " SentiSynset('plant.n.04'),\n",
       " SentiSynset('plant.v.01'),\n",
       " SentiSynset('implant.v.01'),\n",
       " SentiSynset('establish.v.02'),\n",
       " SentiSynset('plant.v.04'),\n",
       " SentiSynset('plant.v.05'),\n",
       " SentiSynset('plant.v.06')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swn.senti_synsets(\"plant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are approximately sorted in frequency of usage. Now, we can use the SWN dictionary like so, when parsing actual sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we take a sentence and split it into tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'red',\n",
       " 'car',\n",
       " 'is',\n",
       " 'horrible',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'broken',\n",
       " 'car',\n",
       " '.',\n",
       " 'I',\n",
       " 'want',\n",
       " 'to',\n",
       " 'punch',\n",
       " 'it',\n",
       " '.']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = \"This red car is horrible. It is a very broken car. I want to punch it.\"\n",
    "tokens = nltk.word_tokenize(article)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we tag these tokens according to what parts of speech they might be (noun, verb, etc):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('red', 'JJ'),\n",
       " ('car', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('horrible', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('very', 'RB'),\n",
       " ('broken', 'JJ'),\n",
       " ('car', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('punch', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "tagged_tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have enough information to look up words properly.\n",
    "\n",
    "Here is the meaning of all the tags (e.g. JJ, NN, VB, etc): https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "Unfortunately SentiWordNet and NLTK use different notations for these. Here is one way where we can map the tags from one system to another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk_to_sentiwordnet = {\n",
    "    \"NN\": \"n\",\n",
    "    \"VB\": \"v\",\n",
    "    \"JJ\": \"a\",\n",
    "    \"RB\": \"r\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that, we can try looking up the sentiments for each token in the sentence in SentiWordNet, and print the top results for meanings that we find, along with the definition, the positive score, the negative score and the objectivity score. These scores are normalized such that they add up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red:\n",
      "(SentiSynset('red.s.01'), 0.0, 0.0, 1.0)\n",
      "     of a color at the end of the color spectrum (next to orange); resembling the color of blood or cherries or tomatoes or rubies\n",
      "(SentiSynset('crimson.s.02'), 0.25, 0.625, 0.125)\n",
      "     characterized by violence or bloodshed\n",
      "(SentiSynset('crimson.s.03'), 0.0, 0.25, 0.75)\n",
      "     (especially of the face) reddened or suffused with or as if with blood from emotion or exertion\n",
      "------\n",
      "car:\n",
      "(SentiSynset('car.n.01'), 0.0, 0.0, 1.0)\n",
      "     a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      "(SentiSynset('car.n.02'), 0.0, 0.0, 1.0)\n",
      "     a wheeled vehicle adapted to the rails of railroad\n",
      "(SentiSynset('car.n.03'), 0.0, 0.0, 1.0)\n",
      "     the compartment that is suspended from an airship and that carries personnel and the cargo and the power plant\n",
      "------\n",
      "is:\n",
      "(SentiSynset('be.v.01'), 0.25, 0.125, 0.625)\n",
      "     have the quality of being; (copula, used with an adjective or a predicate noun)\n",
      "(SentiSynset('be.v.02'), 0.0, 0.0, 1.0)\n",
      "     be identical to; be someone or something\n",
      "(SentiSynset('be.v.03'), 0.0, 0.0, 1.0)\n",
      "     occupy a certain position or area; be somewhere\n",
      "------\n",
      "horrible:\n",
      "(SentiSynset('atrocious.s.03'), 0.0, 0.625, 0.375)\n",
      "     provoking horror\n",
      "------\n",
      "is:\n",
      "(SentiSynset('be.v.01'), 0.25, 0.125, 0.625)\n",
      "     have the quality of being; (copula, used with an adjective or a predicate noun)\n",
      "(SentiSynset('be.v.02'), 0.0, 0.0, 1.0)\n",
      "     be identical to; be someone or something\n",
      "(SentiSynset('be.v.03'), 0.0, 0.0, 1.0)\n",
      "     occupy a certain position or area; be somewhere\n",
      "------\n",
      "very:\n",
      "(SentiSynset('very.r.01'), 0.25, 0.25, 0.5)\n",
      "     used as intensifiers; `real' is sometimes used informally for `really'; `rattling' is informal\n",
      "(SentiSynset('very.r.02'), 0.25, 0.0, 0.75)\n",
      "     precisely so\n",
      "------\n",
      "broken:\n",
      "(SentiSynset('broken.a.01'), 0.0, 0.125, 0.875)\n",
      "     physically and forcibly separated into pieces or cracked or split\n",
      "(SentiSynset('broken.a.02'), 0.0, 0.125, 0.875)\n",
      "     not continuous in space, time, or sequence or varying abruptly\n",
      "(SentiSynset('broken.s.03'), 0.0, 0.375, 0.625)\n",
      "     subdued or brought low in condition or status\n",
      "------\n",
      "car:\n",
      "(SentiSynset('car.n.01'), 0.0, 0.0, 1.0)\n",
      "     a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      "(SentiSynset('car.n.02'), 0.0, 0.0, 1.0)\n",
      "     a wheeled vehicle adapted to the rails of railroad\n",
      "(SentiSynset('car.n.03'), 0.0, 0.0, 1.0)\n",
      "     the compartment that is suspended from an airship and that carries personnel and the cargo and the power plant\n",
      "------\n",
      "want:\n",
      "(SentiSynset('desire.v.01'), 0.25, 0.0, 0.75)\n",
      "     feel or have a desire for; want strongly\n",
      "(SentiSynset('want.v.02'), 0.125, 0.125, 0.75)\n",
      "     have need of\n",
      "(SentiSynset('want.v.03'), 0.0, 0.0, 1.0)\n",
      "     hunt or look for; want for a particular reason\n",
      "------\n",
      "punch:\n",
      "(SentiSynset('punch.v.01'), 0.0, 0.0, 1.0)\n",
      "     deliver a quick blow to\n",
      "(SentiSynset('punch.v.02'), 0.0, 0.0, 1.0)\n",
      "     drive forcibly as if by a punch\n",
      "(SentiSynset('punch.v.03'), 0.0, 0.0, 1.0)\n",
      "     make a hole into or between, as for ease of separation\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for word, pos in tagged_tokens:\n",
    "    \n",
    "    swn_pos = nltk_to_sentiwordnet.get(pos[:2], None)\n",
    "    \n",
    "    if swn_pos == None:\n",
    "        continue\n",
    "    \n",
    "    synsets = swn.senti_synsets(word.lower(), pos=swn_pos)\n",
    "    \n",
    "    if len(synsets) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(\"{}:\".format(word))\n",
    "    for synset in synsets[:3]:\n",
    "        print(synset, synset.pos_score(), synset.neg_score(), synset.obj_score())\n",
    "        print \"    \", synset.synset.definition()\n",
    "    print(\"------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now this leaves us with a few problems to solve further:\n",
    "\n",
    "#### How do we disambiguate between the multiple senses of words?\n",
    "\n",
    "A naive option is to choose the first word - senses that have opposite sentiment are an edge case, and mistakes here shouldn't have a huge effect given that our large article size. Among hundreds of words, this is not a huge deal.\n",
    "\n",
    "A more advanced solution is to use Word Sense Disambiguation (e.g. the Lesk algorithm) to get a best guess of which sense of the word is being used. This is computationally expensive, but there are libraries to do this, e.g. [pyWSD](https://github.com/alvations/pywsd).\n",
    "\n",
    "#### What do we do with words that we don't find?\n",
    "\n",
    "This is easy, we can just skip the words - it's the same as no sentiment data.\n",
    "\n",
    "#### How do we combine the three scores (Positivity, Negativity, Objectivity) to get one score? \n",
    "\n",
    "One option is to turn the result into a single result, with a formula like: (P-N) * (1 - O).\n",
    "\n",
    "But thinking further, do we really need to get a final binary Positive / Negative score? Isn't this a loss of valuable information? Perhaps it is a better choice not combine them and keep them as separate features and include them that way in the model.\n",
    "\n",
    "#### How do we combine word scores into an article scores?\n",
    "\n",
    "One way is to sum the scores across words, but that's not a great idea since article sizes and also the  can be quite different. A better way seems to be to average them, preferably to do a weighted average based on the subjectivity of the words.\n",
    "\n",
    "#### Do we filter out useless words during that process?\n",
    "\n",
    "Another thought is to filter most of the high objectivity words (e.g. \"Potato\" rather than \"Great\"). These don't necessarily add much value in terms of sentiment information, and dilute real information, so perhaps we'd rather toss them out or reduce their effect by some weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An experiment in Word Sense Disambiguation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To install pyWSD, run the command below: \n",
    "# !pip install git+https://github.com/alvations/pywsd.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pywsd import disambiguate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car <car.n.04: PosScore=0.0 NegScore=0.0> 1.0\n",
      "broken <broken.a.04: PosScore=0.0 NegScore=0.125> 0.875\n",
      "car <car.n.04: PosScore=0.0 NegScore=0.0> 1.0\n",
      "want <want.v.05: PosScore=0.0 NegScore=0.625> 0.375\n",
      "punch <punch.v.03: PosScore=0.0 NegScore=0.0> 1.0\n"
     ]
    }
   ],
   "source": [
    "disambiguated_sentence = disambiguate(sentence)\n",
    "for word, synset in disambiguated_sentence:\n",
    "    if synset:\n",
    "        senti_synset = swn.senti_synset(synset._name)\n",
    "        print word, senti_synset, senti_synset.obj_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason this seems to eat up some words. For example, where is \"horrible\"? It turns out that the disambiguate() function doesn't return anything if the word does not have more than one meaning. We can try to remedy that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disambiguated_sentence = disambiguate(sentence)\n",
    "for word, synset in disambiguated_sentence:\n",
    "    if synset:\n",
    "        senti_synset = swn.senti_synset(synset._name)\n",
    "        print word, senti_synset, senti_synset.obj_score()\n",
    "    else:\n",
    "        senti_synsets = swn.senti_synsets(word)\n",
    "        if len(senti_synsets) == 1:\n",
    "            print word, senti_synsets[0], senti_synsets[0].obj_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still some stuff is missing. Where is \"red\"? Until this is resolved, I'll opt to not use WSD. Here is a full implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import numpy as np\n",
    "\n",
    "#nltk.download(\"sentiwordnet\")\n",
    "#nltk.download(\"stopwords\")\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "english_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "nltk_to_sentiwordnet = {\n",
    "    \"NN\": \"n\",\n",
    "    \"VB\": \"v\",\n",
    "    \"JJ\": \"a\",\n",
    "    \"RB\": \"r\",\n",
    "}\n",
    "\n",
    "def get_sentiment(article):\n",
    "    \n",
    "    sentences = nltk.sent_tokenize(article)\n",
    "    sentence_words = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "    tagged_sentence_words = flatten(nltk.pos_tag_sents(sentence_words))\n",
    "    \n",
    "    # Filter stopwords\n",
    "    tagged_sentence_words = [word for word in tagged_sentence_words if word[1] not in english_stopwords]\n",
    "    \n",
    "    pos_scores = []\n",
    "    neg_scores = []\n",
    "    subj_scores = []\n",
    "\n",
    "    for word, pos in tagged_sentence_words:\n",
    "        \n",
    "        swn_pos = nltk_to_sentiwordnet.get(pos[:2], None)\n",
    "    \n",
    "        if swn_pos == None:\n",
    "            continue\n",
    "    \n",
    "        synsets = swn.senti_synsets(word.lower(), pos=swn_pos)\n",
    "    \n",
    "        if len(synsets) == 0:\n",
    "            continue\n",
    "    \n",
    "        #print(\"{}:\".format(word))\n",
    "        for synset in synsets[:1]:\n",
    "            pos_scores.append(synset.pos_score())\n",
    "            neg_scores.append(synset.neg_score())\n",
    "            subj_scores.append(1 - synset.obj_score())\n",
    "        \n",
    "    return np.average(pos_scores, weights=subj_scores) , np.average(neg_scores, weights=subj_scores), np.mean(subj_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16666666666666666, 0.27777777777777779, 0.22500000000000001)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39166666666666666, 0.066666666666666666, 0.20833333333333334)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(\"This car is amazing. I really love the detailing and the finish. It's just the way I like it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
